{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2530487,"sourceType":"datasetVersion","datasetId":1533360}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport torch\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nfrom torchvision.models import efficientnet_b4, EfficientNet_B4_Weights\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix\nfrom PIL import Image\nfrom typing import Tuple, List, Dict\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T11:15:30.823599Z","iopub.execute_input":"2025-02-21T11:15:30.824017Z","iopub.status.idle":"2025-02-21T11:15:30.829673Z","shell.execute_reply.started":"2025-02-21T11:15:30.823979Z","shell.execute_reply":"2025-02-21T11:15:30.828817Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Configuration\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nIMG_SIZE = (380, 380)\nBATCH_SIZE = 32\nEPOCHS_PHASE1 = 15\nEPOCHS_PHASE2 = 10\nCLASS_NAMES = ['DR', 'MH', 'ODC', 'TSLN', 'DN', 'MYA', 'ARMD', 'BRVO', 'ODP', 'ODE', 'LS', 'RS', 'CSR', 'CRS']\n\n# Set random seeds\ntorch.manual_seed(42)\nnp.random.seed(42)\n\ndef load_and_preprocess_data():\n    train_labels = pd.read_csv(\"/kaggle/input/retinal-disease-classification/Training_Set/Training_Set/RFMiD_Training_Labels.csv\")\n    val_labels = pd.read_csv(\"/kaggle/input/retinal-disease-classification/Evaluation_Set/Evaluation_Set/RFMiD_Validation_Labels.csv\")\n    test_labels = pd.read_csv(\"/kaggle/input/retinal-disease-classification/Test_Set/Test_Set/RFMiD_Testing_Labels.csv\")\n    \n    def process_df(df):\n        selected_diseases = list(set(CLASS_NAMES) & set(df.columns))\n        df = df[['ID', 'Disease_Risk'] + selected_diseases].copy()\n        df['Disease_Risk'] = (df[selected_diseases].sum(axis=1) > 0).astype(int)\n        return df\n    \n    return process_df(train_labels), process_df(val_labels), process_df(test_labels)\n\nclass RetinalDataset(Dataset):\n    def __init__(self, img_dir: str, df: pd.DataFrame, transform=None, augment=False, mixup_alpha=0.4):\n        self.img_dir = img_dir\n        self.df = df\n        self.transform = transform\n        self.augment = augment\n        self.mixup_alpha = mixup_alpha\n        self.image_paths = [os.path.join(img_dir, f\"{row['ID']}.png\") for _, row in df.iterrows()]\n\n    def __len__(self):\n        return len(self.df)\n        \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        # Use PIL's resize during loading to reduce memory usage\n        image = Image.open(img_path).convert('RGB').resize((320, 320))  # Reduced size\n        \n        if self.transform:\n            image = self.transform(image=np.array(image))['image']\n        \n        labels = torch.tensor(self.df.iloc[idx][CLASS_NAMES].values, dtype=torch.float32)\n        \n        return image, labels\n\n    def mixup_data(self, x: torch.Tensor, y: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n        if self.mixup_alpha > 0:\n            lam = np.clip(np.random.beta(self.mixup_alpha, self.mixup_alpha), 0.2, 0.8)\n            batch_size = x.size()[0]\n            index = torch.randperm(batch_size).to(x.device)\n            \n            mixed_x = lam * x + (1 - lam) * x[index]\n            mixed_y = lam * y + (1 - lam) * y[index]\n            return mixed_x, mixed_y\n        return x, y\n\nclass RetinalModel(nn.Module):\n    def __init__(self, num_classes: int):\n        super().__init__()\n        weights = EfficientNet_B4_Weights.DEFAULT\n        self.backbone = efficientnet_b4(weights=weights)\n        num_features = self.backbone.classifier[1].in_features\n        self.backbone.classifier = nn.Identity()\n        \n        self.classifier = nn.Sequential(\n            nn.BatchNorm1d(num_features),\n            nn.Dropout(0.5),\n            nn.Linear(num_features, 512),\n            nn.SiLU(),\n            nn.BatchNorm1d(512),\n            nn.Dropout(0.5),\n            nn.Linear(512, 256),\n            nn.SiLU(),\n            nn.Linear(256, num_classes),\n        )\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.backbone(x)\n        return self.classifier(x)\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=0.25, gamma=2.0):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        \n    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n        # bce_loss = nn.BCELoss(reduction='none')(inputs, targets)\n        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n        pt = torch.exp(-bce_loss)\n        focal_loss = self.alpha * (1-pt)**self.gamma * bce_loss\n        return focal_loss.mean()\n\ndef train_epoch(model: nn.Module, dataloader: DataLoader, criterion, optimizer, scaler, device: torch.device) -> Tuple[float, float]:\n    model.train()\n    total_loss = 0\n    total_auc = 0\n    \n    for batch_idx, (images, targets) in enumerate(dataloader):\n        # Clear cache periodically\n        if batch_idx % 10 == 0:\n            torch.cuda.empty_cache()\n            gc.collect()\n            \n        images = images.to(device, non_blocking=True)\n        targets = targets.to(device, non_blocking=True)\n        \n        if dataloader.dataset.augment:\n            images, targets = dataloader.dataset.mixup_data(images, targets)\n        \n        optimizer.zero_grad(set_to_none=True)  # More efficient than zero_grad()\n        \n        with torch.amp.autocast('cuda'):  # Use mixed precision\n            outputs = model(images)\n            loss = criterion(outputs, targets)\n       \n        # Use scaler for mixed precision training\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        \n        # loss.backward()\n        # optimizer.step()\n\n         \n        # For AUC calculation, apply sigmoid to get probabilities\n        with torch.no_grad():\n            probs = torch.sigmoid(outputs)\n        \n        try:\n            auc = roc_auc_score(targets.cpu().numpy(), probs.cpu().numpy(), average='macro')\n            total_auc += auc\n        except:\n            pass\n\n\n        total_loss += loss.item()\n        del images, targets, outputs, probs\n        torch.cuda.empty_cache()\n        \n        # # Explicitly clear variables\n        # del images, targets, outputs\n        # torch.cuda.empty_cache()\n        \n        # total_loss += loss.item()\n        # try:\n        #     auc = roc_auc_score(targets.cpu().numpy(), outputs.detach().cpu().numpy(), average='macro')\n        #     total_auc += auc\n        # except:\n        #     pass\n            \n    return total_loss / len(dataloader), total_auc / len(dataloader)\n\n\ndef validate(model: nn.Module, dataloader: DataLoader, criterion, device: torch.device) -> Tuple[float, float]:\n    model.eval()\n    total_loss = 0\n    total_auc = 0\n    \n    with torch.no_grad():\n        for images, targets in dataloader:\n            images = images.to(device, non_blocking=True)\n            targets = targets.to(device, non_blocking=True)\n            \n            outputs = model(images)\n            loss = criterion(outputs, targets)\n\n            # Apply sigmoid for predictions\n            probs = torch.sigmoid(outputs)\n            \n            total_loss += loss.item()\n            try:\n                auc = roc_auc_score(targets.cpu().numpy(), probs.cpu().numpy(), average='macro')\n                total_auc += auc\n            except:\n                pass\n            \n    return total_loss / len(dataloader), total_auc / len(dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T11:15:31.881587Z","iopub.execute_input":"2025-02-21T11:15:31.881966Z","iopub.status.idle":"2025-02-21T11:15:31.904792Z","shell.execute_reply.started":"2025-02-21T11:15:31.881917Z","shell.execute_reply":"2025-02-21T11:15:31.904042Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def main():\n\n    # Configure for memory efficiency\n    torch.backends.cudnn.benchmark = True\n\n    # Load data\n    train_df, val_df, test_df = load_and_preprocess_data()\n    \n    # Define transforms\n    train_transform = A.Compose([\n        A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n        A.RandomRotate90(),\n        A.HorizontalFlip(),\n        A.VerticalFlip(),\n        # A.OneOf([\n        #     A.RandomBrightness(),\n        #     A.RandomContrast(),\n        # ], p=0.3),\n        A.Normalize(),\n        ToTensorV2()\n    ])\n    \n    val_transform = A.Compose([\n        A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n        A.Normalize(),\n        ToTensorV2()\n    ])\n    \n    # Create datasets and dataloaders\n    train_dataset = RetinalDataset(\n        \"/kaggle/input/retinal-disease-classification/Training_Set/Training_Set/Training\",\n        train_df,\n        transform=train_transform,\n        augment=True,\n        mixup_alpha=0.4\n    )\n    \n    val_dataset = RetinalDataset(\n        \"/kaggle/input/retinal-disease-classification/Evaluation_Set/Evaluation_Set/Validation\",\n        val_df,\n        transform=val_transform\n    )\n    \n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True, persistent_workers=True)\n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True, persistent_workers=True)\n\n    # Initialize mixed precision training\n    scaler = torch.amp.GradScaler(device='cuda')\n    \n    # Initialize model, criterion, and optimizer\n    model = RetinalModel(len(CLASS_NAMES)).to(DEVICE)\n    criterion = FocalLoss(alpha=0.25, gamma=2.0)\n    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n    scaler = torch.amp.GradScaler(device='cuda')\n    \n    # Training Phase 1\n    best_val_auc = 0\n    for epoch in range(EPOCHS_PHASE1):\n        # Clear memory before each epoch\n        torch.cuda.empty_cache()\n        gc.collect()\n        \n        train_loss, train_auc = train_epoch(model, train_loader, criterion, optimizer, scaler, DEVICE)\n        \n        with torch.no_grad():  # Ensure validation doesn't accumulate gradients\n            val_loss, val_auc = validate(model, val_loader, criterion, DEVICE)\n        \n        scheduler.step(val_auc)\n        \n        if val_auc > best_val_auc or epoch == 0:\n            best_val_auc = val_auc\n            print(\"Our model: \\n\\n\", model, '\\n')\n            print(\"The state dict keys: \\n\\n\", model.state_dict().keys())\n            try:\n                torch.save(model.state_dict(), '/kaggle/working/phase1_best.pth')\n                print(\"Checkpoint saved successfully!\")\n            except Exception as e:\n                print(f\"Error while saving model: {e}\")\n\n        print(f'Epoch {epoch+1}/{EPOCHS_PHASE1}:')\n        print(f'Train Loss: {train_loss:.4f}, Train AUC: {train_auc:.4f}')\n        print(f'Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}')\n        \n        # Clear memory after each epoch\n        torch.cuda.empty_cache()\n        gc.collect()\n    \n    # Phase 2: Fine-tuning\n    model.load_state_dict(torch.load('/kaggle/working/phase1_best.keras'))\n    for param in model.backbone.parameters():\n        param.requires_grad = True\n        \n    optimizer = optim.Adam(model.parameters(), lr=1e-5)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.2, patience=1)\n    \n    for epoch in range(EPOCHS_PHASE2):\n        train_loss, train_auc = train_epoch(model, train_loader, criterion, optimizer, DEVICE)\n        val_loss, val_auc = validate(model, val_loader, criterion, DEVICE)\n        \n        scheduler.step(val_auc)\n        \n        if val_auc > best_val_auc or epoch == 0:\n            best_val_auc = val_auc\n            print(\"Our model: \\n\\n\", model, '\\n')\n            print(\"The state dict keys: \\n\\n\", model.state_dict().keys())\n            try:\n                torch.save(model.state_dict(), '/kaggle/working/final_model.keras')\n                print(\"2nd Checkpoint saved successfully!\")\n            except Exception as e:\n                print(f\"Error while saving model: {e}\")\n            \n        print(f'Fine-tuning Epoch {epoch+1}/{EPOCHS_PHASE2}:')\n        print(f'Train Loss: {train_loss:.4f}, Train AUC: {train_auc:.4f}')\n        print(f'Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}')\n        \n    \n    # Compute final AUC across full validation set\n    all_labels, all_probs = [], []\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            outputs = model(images)\n            probs = torch.sigmoid(outputs)  # Convert logits to probabilities\n            \n            all_labels.append(labels.cpu().numpy())\n            all_probs.append(probs.cpu().numpy())\n    \n    all_labels = np.concatenate(all_labels, axis=0)\n    all_probs = np.concatenate(all_probs, axis=0)\n    \n    if len(np.unique(all_labels)) > 1:  # Ensure at least two classes exist\n        auc_score = roc_auc_score(all_labels, all_probs)\n        print(f'Final Validation AUC Score: {auc_score:.4f}')\n    else:\n        print(\"Warning: Only one class present in validation set. AUC cannot be computed.\")\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T11:15:32.855426Z","iopub.execute_input":"2025-02-21T11:15:32.855789Z","iopub.status.idle":"2025-02-21T12:14:15.963685Z","shell.execute_reply.started":"2025-02-21T11:15:32.855739Z","shell.execute_reply":"2025-02-21T12:14:15.962052Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/15:\nTrain Loss: 0.0176, Train AUC: 0.0000\nVal Loss: 0.0120, Val AUC: 0.0000\nEpoch 2/15:\nTrain Loss: 0.0114, Train AUC: 0.0000\nVal Loss: 0.0118, Val AUC: 0.0000\nEpoch 3/15:\nTrain Loss: 0.0108, Train AUC: 0.0000\nVal Loss: 0.0104, Val AUC: 0.0000\nEpoch 4/15:\nTrain Loss: 0.0102, Train AUC: 0.0000\nVal Loss: 0.0098, Val AUC: 0.0000\nEpoch 5/15:\nTrain Loss: 0.0092, Train AUC: 0.0000\nVal Loss: 0.0085, Val AUC: 0.0000\nEpoch 6/15:\nTrain Loss: 0.0092, Train AUC: 0.0000\nVal Loss: 0.0087, Val AUC: 0.0000\nEpoch 7/15:\nTrain Loss: 0.0087, Train AUC: 0.0000\nVal Loss: 0.0082, Val AUC: 0.0000\nEpoch 8/15:\nTrain Loss: 0.0083, Train AUC: 0.0000\nVal Loss: 0.0078, Val AUC: 0.0000\nEpoch 9/15:\nTrain Loss: 0.0082, Train AUC: 0.0000\nVal Loss: 0.0077, Val AUC: 0.0000\nEpoch 10/15:\nTrain Loss: 0.0080, Train AUC: 0.0000\nVal Loss: 0.0075, Val AUC: 0.0000\nEpoch 11/15:\nTrain Loss: 0.0079, Train AUC: 0.0000\nVal Loss: 0.0076, Val AUC: 0.0000\nEpoch 12/15:\nTrain Loss: 0.0077, Train AUC: 0.0000\nVal Loss: 0.0076, Val AUC: 0.0000\nEpoch 13/15:\nTrain Loss: 0.0077, Train AUC: 0.0000\nVal Loss: 0.0075, Val AUC: 0.0000\nEpoch 14/15:\nTrain Loss: 0.0077, Train AUC: 0.0000\nVal Loss: 0.0074, Val AUC: 0.0000\nEpoch 15/15:\nTrain Loss: 0.0075, Train AUC: 0.0000\nVal Loss: 0.0074, Val AUC: 0.0000\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-6-f5e57105ad9e>:90: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('phase1_best.pth'))\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-f5e57105ad9e>\u001b[0m in \u001b[0;36m<cell line: 139>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-f5e57105ad9e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# Phase 2: Fine-tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'phase1_best.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1317\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'phase1_best.pth'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'phase1_best.pth'","output_type":"error"}],"execution_count":6},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.metrics import AUC\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\nfrom tensorflow.keras.applications import EfficientNetB4\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.losses import BinaryFocalCrossentropy\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nfrom tensorflow.keras.utils import to_categorical\nfrom concurrent.futures import ThreadPoolExecutor","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#### print(\"Available GPUs:\", tf.config.list_physical_devices('GPU'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n            print(\"GPU Done!!\")\n    except RuntimeError as e:\n        print(e)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"policy = tf.keras.mixed_precision.Policy('mixed_float16')\ntf.keras.mixed_precision.set_global_policy(policy)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set random seed for reproducibility\ntf.random.set_seed(42)\nnp.random.seed(42)\n\n# Configuration\nIMG_SIZE = (380, 380)  # EfficientNetB4 requires 380x380\nBATCH_SIZE = 64\nEPOCHS_PHASE1 = 15\nEPOCHS_PHASE2 = 10\nCLASS_NAMES = ['DR', 'MH', 'ODC', 'TSLN', 'DN', 'MYA', 'ARMD', 'BRVO', 'ODP', 'ODE', 'LS', 'RS', 'CSR', 'CRS']\n\n# Paths\ntrain_labels_path = \"/kaggle/input/retinal-disease-classification/Training_Set/Training_Set/RFMiD_Training_Labels.csv\"\nval_labels_path = \"/kaggle/input/retinal-disease-classification/Evaluation_Set/Evaluation_Set/RFMiD_Validation_Labels.csv\"\ntest_labels_path = \"/kaggle/input/retinal-disease-classification/Test_Set/Test_Set/RFMiD_Testing_Labels.csv\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load and preprocess data\ndef load_and_preprocess_data():\n    train_labels = pd.read_csv(train_labels_path)\n    val_labels = pd.read_csv(val_labels_path)\n    test_labels = pd.read_csv(test_labels_path)\n\n    selected_diseases = CLASS_NAMES\n    \n    def process_df(df):\n        selected_diseases = list(set(CLASS_NAMES) & set(df.columns))\n        df = df[['ID', 'Disease_Risk'] + selected_diseases].copy()\n        df['Disease_Risk'] = (df[selected_diseases].sum(axis=1) > 0).astype(int)\n        return df\n\n    return (\n        process_df(train_labels),\n        process_df(val_labels),\n        process_df(test_labels)\n    )\n\ntrain_df, val_df, test_df = load_and_preprocess_data()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Enhanced Data Generator with Mixup\nclass AdvancedDataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, img_dir, df, batch_size=32, img_size=IMG_SIZE, \n                 augment=False, shuffle=True, mixup_alpha=0.4, **kwargs):\n        super().__init__(**kwargs) \n         \n        self.img_dir = img_dir\n        self.df = df\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.augment = augment\n        self.shuffle = shuffle\n        self.mixup_alpha = mixup_alpha\n        self.indices = np.arange(len(df))\n        \n        # Pre-load all image paths for faster access\n        self.image_paths = [os.path.join(img_dir, f\"{row['ID']}.png\") for _, row in df.iterrows()]\n\n        # Augmentation configurations\n        self.augmenter = ImageDataGenerator(\n            rotation_range=25,\n            width_shift_range=0.2,\n            height_shift_range=0.2,\n            shear_range=0.2,\n            zoom_range=0.2,\n            horizontal_flip=True,\n            vertical_flip=True,\n            brightness_range=[0.8, 1.2]\n        )\n\n        # Set memory optimization flags\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.ceil(len(self.df) / self.batch_size))\n\n    def __getitem__(self, index):\n        batch_indices = self.indices[index*self.batch_size : (index+1)*self.batch_size]\n        batch_df = self.df.iloc[batch_indices]\n\n        # Use parallel processing for data loading\n        with ThreadPoolExecutor(max_workers=4) as executor:\n            results = list(executor.map(self._load_single_item, batch_indices))\n\n        X = np.stack([r[0] for r in results])\n        y = np.stack([r[1] for r in results])\n\n        # Apply Mixup using vectorized operations\n        if self.augment and self.mixup_alpha > 0:\n            X, y = self._apply_mixup(X, y)\n            \n        return X, y        \n        # # Load images and labels\n        # X, y = self._load_data(batch_df)\n        \n        # # Apply Mixup\n        # if self.augment and self.mixup_alpha > 0:\n        #     X, y = self._apply_mixup(X, y)\n            \n        # return X, y\n\n    def _load_single_item(self, idx):\n        row = self.df.iloc[idx]\n        img = load_img(self.image_paths[idx], target_size=self.img_size)\n        img_array = img_to_array(img)\n        \n        if self.augment and row['Disease_Risk'] == 1:\n            img_array = self.augmenter.random_transform(img_array)\n            \n        return preprocess_input(img_array), row[CLASS_NAMES].values.astype(np.float32)\n    \n    def _apply_mixup(self, X, y):\n        lam = np.clip(np.random.beta(self.mixup_alpha, self.mixup_alpha), 0.2, 0.8)\n        rand_index = np.random.permutation(len(X))\n        \n        # Vectorized operations\n        mixed_X = lam * X + (1 - lam) * X[rand_index]\n        mixed_y = lam * y + (1 - lam) * y[rand_index]\n        return mixed_X, mixed_y\n\n    # def on_epoch_end(self):\n    #     if self.shuffle:\n    #         np.random.shuffle(self.indices)\n\n    # def _load_data(self, batch_df):\n    #     X = np.empty((len(batch_df), *self.img_size, 3))\n    #     y = np.empty((len(batch_df), len(CLASS_NAMES)))   # Disease_Risk + diseases\n        \n    #     for i, (_, row) in enumerate(batch_df.iterrows()):\n    #         img_path = os.path.join(self.img_dir, f\"{row['ID']}.png\")\n    #         img = load_img(img_path, target_size=self.img_size)\n    #         img_array = img_to_array(img)\n            \n    #         # Apply augmentation only to diseased samples\n    #         if self.augment and row['Disease_Risk'] == 1:\n    #             img_array = self.augmenter.random_transform(img_array)\n                \n    #         X[i] = preprocess_input(img_array)  # EfficientNet preprocessing\n    #         y[i] = row[CLASS_NAMES].values\n            \n    #     return X, y.astype(np.float32)\n\n    # def _apply_mixup(self, X, y):\n    #     lam = np.clip(np.random.beta(self.mixup_alpha, self.mixup_alpha), 0.2, 0.8)\n    #     rand_index = np.random.permutation(len(X))\n        \n    #     mixed_X = lam * X + (1 - lam) * X[rand_index]\n    #     mixed_y = lam * y + (1 - lam) * y[rand_index]\n    #     return mixed_X, mixed_y","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create data generators\ntrain_gen = AdvancedDataGenerator(\n    \"/kaggle/input/retinal-disease-classification/Training_Set/Training_Set/Training\",\n    train_df,\n    batch_size=BATCH_SIZE,\n    augment=True,\n    mixup_alpha=0.4\n)\n\nval_gen = AdvancedDataGenerator(\n    \"/kaggle/input/retinal-disease-classification/Evaluation_Set/Evaluation_Set/Validation\",\n    val_df,\n    batch_size=BATCH_SIZE\n)\n\ntest_gen = AdvancedDataGenerator(\n    \"/kaggle/input/retinal-disease-classification/Test_Set/Test_Set/Test\",\n    test_df,\n    batch_size=BATCH_SIZE\n)\n\ndef generator_wrapper(generator):\n    for X, y in generator:\n        yield X, y\n\n# train_dataset = tf.data.Dataset.from_generator(\n#     lambda: generator_wrapper(train_gen),\n#     output_signature=(\n#         tf.TensorSpec(shape=(None, *IMG_SIZE, 3), dtype=tf.float32),\n#         tf.TensorSpec(shape=(None, len(CLASS_NAMES)), dtype=tf.float32)\n#     )\n# ).prefetch(tf.data.AUTOTUNE)\n\ntrain_dataset = tf.data.Dataset.from_generator(\n    lambda: generator_wrapper(train_gen),\n    output_signature=(\n        tf.TensorSpec(shape=(None, *IMG_SIZE, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(None, len(CLASS_NAMES)), dtype=tf.float32)\n    )\n).prefetch(tf.data.AUTOTUNE).cache().shuffle(buffer_size=1000)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_batch, y_batch = train_gen[0]\nprint(\"Shape of X_batch:\", X_batch.shape)  # Should be (batch_size, 380, 380, 3)\nprint(\"Shape of y_batch:\", y_batch.shape)  # Should be (batch_size, 14)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate class weights\ndef calculate_class_weights(df):\n    weights = {}\n    for idx, disease in enumerate(['Disease_Risk'] + CLASS_NAMES):\n        cls_weights = compute_class_weight(\n            'balanced',\n            classes=np.array([0, 1]),\n            y=df[disease]\n        )\n        weights[idx] = {0: cls_weights[0], 1: cls_weights[1]}\n    return weights\n\nclass_weights = calculate_class_weights(train_df)\nclass_weights = {idx: weights[1] for idx, weights in class_weights.items()}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build Model\ndef build_model():\n    base_model = EfficientNetB4(\n        weights='imagenet',\n        include_top=False,\n        input_shape=(*IMG_SIZE, 3)\n    )\n    base_model.trainable = False  # Freeze initially\n\n    model = Sequential([\n        base_model,\n        GlobalAveragePooling2D(),\n        BatchNormalization(),\n        Dropout(0.5),\n        Dense(512, activation='swish', kernel_regularizer=regularizers.l2(1e-4)),\n        BatchNormalization(),\n        Dropout(0.5),\n        Dense(256, activation='swish'),\n        Dense(len(CLASS_NAMES), activation='sigmoid')  # Disease_Risk + diseases\n    ])\n    \n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def focal_loss(alpha=0.25, gamma=2.0):\n    def loss_fn(y_true, y_pred):\n        # Cast to float32\n        y_true = tf.cast(y_true, tf.float32)\n        y_pred = tf.cast(y_pred, tf.float32)\n        \n        # Compute element-wise binary crossentropy using Keras backend.\n        ce = tf.keras.backend.binary_crossentropy(y_true, y_pred)  \n        # ce now has shape (batch_size, num_classes)\n        \n        # Compute p_t element-wise\n        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n        \n        # Compute alpha factor element-wise\n        alpha_factor = y_true * alpha + (1 - y_true) * (1 - alpha)\n        \n        # Compute modulating factor element-wise\n        modulating_factor = tf.pow(1.0 - p_t, gamma)\n        \n        # Final loss element-wise\n        loss = alpha_factor * modulating_factor * ce\n        return loss  # Optionally, you can reduce_mean over the batch or last axis.\n    \n    return loss_fn\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_y_true = tf.convert_to_tensor(y_batch[:5], dtype=tf.float32)  # (5, 14)\nsample_y_pred = tf.random.uniform(sample_y_true.shape, 0, 1)           # (5, 14)\nloss_fn = focal_loss(alpha=0.25, gamma=2.0)\nprint(loss_fn(sample_y_true, sample_y_pred))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"y_true shape:\", sample_y_true.shape)\nprint(\"y_pred shape:\", sample_y_pred.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Two-Phase Training\nmodel = build_model()\n\n# Phase 1: Train head\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n    loss=focal_loss(gamma=2.0, alpha=0.25),\n    metrics=[AUC(name='auc', multi_label=True)]\n)\n\nphase1_callbacks = [\n    EarlyStopping(patience=3, monitor='val_auc', mode='max', verbose=1),\n    ModelCheckpoint('phase1_best.keras', save_best_only=True),\n    ReduceLROnPlateau(factor=0.5, patience=2)\n]\n\nhistory_phase1 = model.fit(\n    train_dataset,\n    validation_data=val_gen,\n    epochs=EPOCHS_PHASE1,\n    callbacks=phase1_callbacks,\n    # workers=4,  # Increase as needed\n    # use_multiprocessing=True\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Phase 2: Fine-tune\nmodel = tf.keras.models.load_model('phase1_best.keras', custom_objects={'loss_fn': focal_loss()}) # Load best weights from phase 1\nmodel.layers[0].trainable = True  # Unfreeze base model\n\n# Set last 150 layers trainable\nfor layer in model.layers[0].layers[-150:]:\n    layer.trainable = True\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n    loss=focal_loss(gamma=2.0, alpha=0.25),\n    metrics=[AUC(name='auc', multi_label=True)]\n)\n\nphase2_callbacks = [\n    EarlyStopping(patience=2, monitor='val_auc', mode='max', verbose=1),\n    ModelCheckpoint('final_model.keras', save_best_only=True),\n    ReduceLROnPlateau(factor=0.2, patience=1)\n]\n\nhistory_phase2 = model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=EPOCHS_PHASE2,\n    callbacks=phase2_callbacks\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluation with Test-Time Augmentation\ndef evaluate_with_tta(model, generator, n_tta=5):\n    y_true, y_pred = [], []\n    # tta_preds = []\n    \n    for i in range(len(generator)):\n        X, y = generator[i]\n        batch_preds = np.zeros_like(y)\n        \n        for _ in range(n_tta):\n            # Create augmented versions\n            aug_X = np.array([generator.augmenter.random_transform(img) for img in X])\n            batch_preds += model.predict(aug_X)\n            \n        # Average predictions\n        batch_preds /= n_tta  # Average predictions\n        y_true.append(y)\n        y_pred.append(batch_preds)\n        # avg_pred = np.mean(batch_preds, axis=0)\n        # tta_preds.append(avg_pred)\n        # y_true.append(y)\n        \n    return np.vstack(y_true), np.vstack(y_pred)\n\nmodel = tf.keras.models.load_model('final_model.keras', custom_objects={'loss_fn': focal_loss()})\ny_true, y_pred = evaluate_with_tta(model, test_gen)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate reports\nprint(\"Classification Report:\")\nprint(classification_report(\n    y_true[:, 1:],  # Skip Disease_Risk\n    (y_pred[:, 1:] > 0.5).astype(int),\n    target_names=CLASS_NAMES\n))\n\nprint(\"\\nConfusion Matrices:\")\nfor idx, disease in enumerate(CLASS_NAMES):\n    cm = confusion_matrix(y_true[:, idx+1], (y_pred[:, idx+1] > 0.5).astype(int))\n    plt.figure()\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title(f\"{disease} Confusion Matrix\")\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot training history\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(history_phase1.history['auc'], label='Phase1 Train')\nplt.plot(history_phase1.history['val_auc'], label='Phase1 Val')\nplt.plot(np.arange(EPOCHS_PHASE1, EPOCHS_PHASE1+len(history_phase2.history['auc'])), \n         history_phase2.history['auc'], label='Phase2 Train')\nplt.plot(np.arange(EPOCHS_PHASE1, EPOCHS_PHASE1+len(history_phase2.history['val_auc'])), \n         history_phase2.history['val_auc'], label='Phase2 Val')\nplt.title('AUC History')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history_phase1.history['loss'], label='Phase1 Train')\nplt.plot(history_phase1.history['val_loss'], label='Phase1 Val')\nplt.plot(np.arange(EPOCHS_PHASE1, EPOCHS_PHASE1+len(history_phase2.history['loss'])), \n         history_phase2.history['loss'], label='Phase2 Train')\nplt.plot(np.arange(EPOCHS_PHASE1, EPOCHS_PHASE1+len(history_phase2.history['val_loss'])), \n         history_phase2.history['val_loss'], label='Phase2 Val')\nplt.title('Loss History')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}